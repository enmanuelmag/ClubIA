{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import io\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "import importlib\n",
    "import numpy as np\n",
    "import tf_functions\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import seaborn as sns\n",
    "import transformer_v2\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from numba import cuda\n",
    "from PIL import Image\n",
    "from collections import Counter\n",
    "from sklearn import preprocessing\n",
    "from nltk.corpus import stopwords\n",
    "from tensorflow.keras import mixed_precision\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "\n",
    "VitModel = transformer_v2.VitModel\n",
    "\n",
    "importlib.reload(tf_functions)\n",
    "warnings.filterwarnings('ignore')\n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "tf.keras.utils.set_random_seed(SEED)\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "### PARAMS DATA\n",
    "SIZE_IMG = 88\n",
    "\n",
    "PATCH_SIZE = 8 # SIZE OF THE PATCHES TO BE EXTRACT FROM THE INPUT IMAGES\n",
    "NUM_PATCHES = (SIZE_IMG // PATCH_SIZE) ** 2\n",
    "\n",
    "PROJECTION_DIM = 512 #256\n",
    "TRANSFORMER_LAYERS = 8 #8\n",
    "NUM_HEADS = 1 #1\n",
    "TRANSFORMER_UNITS = [\n",
    "  PROJECTION_DIM * 2,\n",
    "  PROJECTION_DIM,\n",
    "] # SIZE OF THE TRANSFORMER LAYERS\n",
    "MLP_HEAD_UNITS = [ 512 ] # [ 512 ]\n",
    "\n",
    "### PATHS\n",
    "VERSION_DS = 2\n",
    "TF_RECORD_PATH = '../Data/dataset.tfrecord'\n",
    "DATASET_PATH = '../Bases de Datos/CrisisMMD_v2.0/data_image/' if VERSION_DS == 1 else '../Bases de Datos/Cyclone_Wildfire_Flood_Earthquake_Database/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_url = re.compile(r'(http|ftp|https)://([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:/~+#-]*[\\w@?^=%&/~+#-])?')\n",
    "re_email = re.compile(r'[\\w\\.-]+@[\\w\\.-]+')\n",
    "re_hashtag = re.compile(r'#([^\\s]+)')\n",
    "\n",
    "def clean_str(string):\n",
    "  string = re_url.sub('', string)\n",
    "  string = re.sub(r\"[^A-Za-z0-9(),!?\\'\\#@`]\", \" \", string)\n",
    "  string = re.sub(r\"\\'s\", \" \\'s\", string)\n",
    "  string = re.sub(r\"\\'ve\", \" \\'ve\", string)\n",
    "  string = re.sub(r\"n\\'t\", \" n\\'t\", string)\n",
    "  string = re.sub(r\"\\'re\", \" \\'re\", string)\n",
    "  string = re.sub(r\"\\'d\", \" \\'d\", string)\n",
    "  string = re.sub(r\"\\'ll\", \" \\'ll\", string)\n",
    "  string = re.sub(r\",\", \" , \", string)\n",
    "  string = re.sub(r\"!\", \" ! \", string)\n",
    "  string = re.sub(r\"\\(\", \" \\( \", string)\n",
    "  string = re.sub(r\"\\)\", \" \\) \", string)\n",
    "  string = re.sub(r\"\\?\", \" \\? \", string)\n",
    "  string = re.sub(r\"\\s{2,}\", \" \", string)\n",
    "  string = string.strip().lower().split()\n",
    "  string = [ word for word in string if word not in stop_words ]\n",
    "  return \" \".join(string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_names(ds_path):\n",
    "  class_array = []\n",
    "  for class_name in os.listdir(ds_path):\n",
    "    class_array.append(class_name)\n",
    "  return class_array\n",
    "\n",
    "def get_class_id(class_name):\n",
    "  return class_array.index(class_name)\n",
    "\n",
    "\n",
    "def build_example(path_file, class_name):\n",
    "  n_path = path_file\n",
    "  if not path_file.endswith('.jpeg') and not path_file.endswith('.jpg'):\n",
    "    img_array = Image.open(path_file).convert('RGB')\n",
    "    n_path = path_file.replace('.png', '.jpeg')\n",
    "    img_array.save(n_path)\n",
    "    os.remove(path_file)\n",
    "\n",
    "  path_file = n_path\n",
    "  img_array = open(path_file, 'rb').read()\n",
    "  example = tf.train.Example(\n",
    "    features=tf.train.Features(feature={\n",
    "    'image': tf.train.Feature(bytes_list=tf.train.BytesList(value=[img_array])),\n",
    "    'class_id': tf.train.Feature(int64_list=tf.train.Int64List(value=[get_class_id(class_name)])),\n",
    "    'class_name': tf.train.Feature(bytes_list=tf.train.BytesList(value=[class_name.encode('utf-8')])),\n",
    "    'filepath': tf.train.Feature(bytes_list=tf.train.BytesList(value=[path_file.encode('utf-8')]))\n",
    "  }))\n",
    "  return example\n",
    "\n",
    "def create_tf_record(version, ds_path, out_dir):\n",
    "  writer = tf.io.TFRecordWriter(out_dir)\n",
    "  print('Start writing to {}'.format(out_dir))\n",
    "  if version == 1:\n",
    "    for class_name in os.listdir(ds_path):\n",
    "      for date in os.listdir(f'{ds_path}/{class_name}/'):\n",
    "        for idx, filename in enumerate(os.listdir(f'{ds_path}/{class_name}/{date}/')):\n",
    "          path_file = os.path.join(ds_path, class_name, date, filename)\n",
    "          tf_example = build_example(path_file, class_name)\n",
    "          writer.write(tf_example.SerializeToString())\n",
    "  elif version == 2:\n",
    "    for class_name in os.listdir(ds_path):\n",
    "      for idx, filename in enumerate(os.listdir(f'{ds_path}/{class_name}/')):\n",
    "        path_file = os.path.join(ds_path, class_name, filename)\n",
    "        tf_example = build_example(path_file, class_name)\n",
    "        writer.write(tf_example.SerializeToString())\n",
    "  writer.close()\n",
    "  print('Done')\n",
    "\n",
    "\n",
    "def parse_tfrecord(tfrecord, size):\n",
    "  x = tf.io.parse_single_example(tfrecord, IMAGE_FEATURE_MAP)\n",
    "  x_train = tf.image.decode_jpeg(x['image'], channels=3)\n",
    "  x_train = tf.image.resize(x_train, (size, size))\n",
    "  x_train = preprocess_input(x_train, mode='tf')\n",
    "\n",
    "  class_id = x['class_id']\n",
    "  if class_id is None:\n",
    "    class_id = -1\n",
    "  y_train = tf.cast(class_id, tf.int64)\n",
    "\n",
    "  return ( x_train, y_train )\n",
    "\n",
    "def load_tfrecord_dataset(file_pattern, size):\n",
    "\n",
    "  files = tf.data.Dataset.list_files(file_pattern)\n",
    "  dataset = files.flat_map(tf.data.TFRecordDataset)\n",
    "  dataset = dataset.map(lambda x: parse_tfrecord(x, size))\n",
    "  return dataset\n",
    "\n",
    "IMAGE_FEATURE_MAP = {\n",
    "  'image': tf.io.FixedLenFeature([], tf.string),\n",
    "  'class_id': tf.io.FixedLenFeature([], tf.int64),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_array = get_class_names(DATASET_PATH)\n",
    "pkl.dump(class_array, open('../Data/class_array.pkl', 'wb'))\n",
    "create_tf_record(VERSION_DS, DATASET_PATH, TF_RECORD_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images: 5384\n"
     ]
    }
   ],
   "source": [
    "class_array = pkl.load(open('../Data/class_array.pkl', 'rb'))\n",
    "tf_record = load_tfrecord_dataset(TF_RECORD_PATH, SIZE_IMG)\n",
    "tf_record = tf_record.cache()\n",
    "\n",
    "all_ds_len = sum(1 for _ in tf_record)\n",
    "tf_record = tf_record.shuffle(all_ds_len, seed=SEED)\n",
    "print(f'Total number of images: {all_ds_len}')\n",
    "\n",
    "n_train = int(all_ds_len * 0.8)\n",
    "n_valid = int(all_ds_len * 0.1)\n",
    "n_test = all_ds_len - n_train - n_valid\n",
    "\n",
    "train_ds = tf_record.take(n_train)\n",
    "valid_ds = tf_record.skip(n_train).take(n_valid)\n",
    "test_ds = tf_record.skip(n_train + n_valid).take(n_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "     68/Unknown - 23s 174ms/step - loss: 2.4964 - accuracy: 0.5055\n",
      "Epoch 1: accuracy improved from -inf to 0.50546, saving model to checkpoints\\3_[512]_8_trans_1_heads_121_num_patchs_512_2e-05checkpoint.h5\n",
      "68/68 [==============================] - 38s 402ms/step - loss: 2.4964 - accuracy: 0.5055 - val_loss: 1.0965 - val_accuracy: 0.5260 - lr: 2.0000e-05\n",
      "Epoch 2/200\n",
      "68/68 [==============================] - ETA: 0s - loss: 1.0921 - accuracy: 0.5127\n",
      "Epoch 2: accuracy improved from 0.50546 to 0.51265, saving model to checkpoints\\3_[512]_8_trans_1_heads_121_num_patchs_512_2e-05checkpoint.h5\n",
      "68/68 [==============================] - 18s 268ms/step - loss: 1.0921 - accuracy: 0.5127 - val_loss: 1.0986 - val_accuracy: 0.4926 - lr: 2.0000e-05\n",
      "Epoch 3/200\n",
      "68/68 [==============================] - ETA: 0s - loss: 1.0886 - accuracy: 0.5134\n",
      "Epoch 3: accuracy improved from 0.51265 to 0.51335, saving model to checkpoints\\3_[512]_8_trans_1_heads_121_num_patchs_512_2e-05checkpoint.h5\n",
      "68/68 [==============================] - 18s 261ms/step - loss: 1.0886 - accuracy: 0.5134 - val_loss: 1.0986 - val_accuracy: 0.5093 - lr: 2.0000e-05\n",
      "Epoch 4/200\n",
      "68/68 [==============================] - ETA: 0s - loss: 1.0958 - accuracy: 0.5173\n",
      "Epoch 4: accuracy improved from 0.51335 to 0.51730, saving model to checkpoints\\3_[512]_8_trans_1_heads_121_num_patchs_512_2e-05checkpoint.h5\n",
      "68/68 [==============================] - 18s 263ms/step - loss: 1.0958 - accuracy: 0.5173 - val_loss: 1.0986 - val_accuracy: 0.5706 - lr: 2.0000e-05\n",
      "Epoch 5/200\n",
      "68/68 [==============================] - ETA: 0s - loss: 1.0960 - accuracy: 0.5222\n",
      "Epoch 5: accuracy improved from 0.51730 to 0.52217, saving model to checkpoints\\3_[512]_8_trans_1_heads_121_num_patchs_512_2e-05checkpoint.h5\n",
      "68/68 [==============================] - 18s 259ms/step - loss: 1.0960 - accuracy: 0.5222 - val_loss: 1.0986 - val_accuracy: 0.5669 - lr: 2.0000e-05\n",
      "Epoch 6/200\n",
      "68/68 [==============================] - ETA: 0s - loss: 1.0953 - accuracy: 0.5205\n",
      "Epoch 6: accuracy did not improve from 0.52217\n",
      "68/68 [==============================] - 17s 245ms/step - loss: 1.0953 - accuracy: 0.5205 - val_loss: 1.0986 - val_accuracy: 0.6004 - lr: 2.0000e-05\n",
      "Epoch 7/200\n",
      "68/68 [==============================] - ETA: 0s - loss: 1.0955 - accuracy: 0.5064\n",
      "Epoch 7: accuracy did not improve from 0.52217\n",
      "68/68 [==============================] - 17s 253ms/step - loss: 1.0955 - accuracy: 0.5064 - val_loss: 1.0986 - val_accuracy: 0.5260 - lr: 2.0000e-05\n",
      "Epoch 8/200\n",
      "68/68 [==============================] - ETA: 0s - loss: 1.0919 - accuracy: 0.5331\n",
      "Epoch 8: accuracy improved from 0.52217 to 0.53309, saving model to checkpoints\\3_[512]_8_trans_1_heads_121_num_patchs_512_2e-05checkpoint.h5\n",
      "68/68 [==============================] - 18s 263ms/step - loss: 1.0919 - accuracy: 0.5331 - val_loss: 1.0986 - val_accuracy: 0.5520 - lr: 2.0000e-05\n",
      "Epoch 9/200\n",
      "68/68 [==============================] - ETA: 0s - loss: 1.0927 - accuracy: 0.5319\n",
      "Epoch 9: accuracy did not improve from 0.53309\n",
      "68/68 [==============================] - 17s 253ms/step - loss: 1.0927 - accuracy: 0.5319 - val_loss: 1.0986 - val_accuracy: 0.5576 - lr: 2.0000e-05\n",
      "Epoch 10/200\n",
      "68/68 [==============================] - ETA: 0s - loss: 1.0914 - accuracy: 0.5212\n",
      "Epoch 10: accuracy did not improve from 0.53309\n",
      "68/68 [==============================] - 17s 254ms/step - loss: 1.0914 - accuracy: 0.5212 - val_loss: 1.0986 - val_accuracy: 0.5260 - lr: 2.0000e-05\n",
      "Epoch 11/200\n",
      "68/68 [==============================] - ETA: 0s - loss: 1.0937 - accuracy: 0.5310\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 1.9999999494757505e-06.\n",
      "\n",
      "Epoch 11: accuracy did not improve from 0.53309\n",
      "68/68 [==============================] - 18s 259ms/step - loss: 1.0937 - accuracy: 0.5310 - val_loss: 1.0986 - val_accuracy: 0.5651 - lr: 2.0000e-05\n",
      "Epoch 12/200\n",
      "68/68 [==============================] - ETA: 0s - loss: 1.0954 - accuracy: 0.5199\n",
      "Epoch 12: accuracy did not improve from 0.53309\n",
      "68/68 [==============================] - 17s 252ms/step - loss: 1.0954 - accuracy: 0.5199 - val_loss: 1.0986 - val_accuracy: 0.5390 - lr: 2.0000e-06\n",
      "Epoch 13/200\n",
      "68/68 [==============================] - ETA: 0s - loss: 1.0934 - accuracy: 0.5134\n",
      "Epoch 13: accuracy did not improve from 0.53309\n",
      "68/68 [==============================] - 17s 252ms/step - loss: 1.0934 - accuracy: 0.5134 - val_loss: 1.0986 - val_accuracy: 0.5204 - lr: 2.0000e-06\n",
      "Epoch 14/200\n",
      "68/68 [==============================] - ETA: 0s - loss: 1.0929 - accuracy: 0.5122\n",
      "Epoch 14: accuracy did not improve from 0.53309\n",
      "68/68 [==============================] - 17s 254ms/step - loss: 1.0929 - accuracy: 0.5122 - val_loss: 1.0986 - val_accuracy: 0.5409 - lr: 2.0000e-06\n",
      "Epoch 15/200\n",
      "68/68 [==============================] - ETA: 0s - loss: 1.0961 - accuracy: 0.5138\n",
      "Epoch 15: accuracy did not improve from 0.53309\n",
      "68/68 [==============================] - 17s 252ms/step - loss: 1.0961 - accuracy: 0.5138 - val_loss: 1.0986 - val_accuracy: 0.5428 - lr: 2.0000e-06\n",
      "Epoch 16/200\n",
      "68/68 [==============================] - ETA: 0s - loss: 1.0936 - accuracy: 0.5068\n",
      "Epoch 16: accuracy did not improve from 0.53309\n",
      "68/68 [==============================] - 17s 251ms/step - loss: 1.0936 - accuracy: 0.5068 - val_loss: 1.0986 - val_accuracy: 0.4926 - lr: 2.0000e-06\n",
      "Epoch 17/200\n",
      "68/68 [==============================] - ETA: 0s - loss: 1.0927 - accuracy: 0.5233\n",
      "Epoch 17: accuracy did not improve from 0.53309\n",
      "68/68 [==============================] - 17s 252ms/step - loss: 1.0927 - accuracy: 0.5233 - val_loss: 1.0986 - val_accuracy: 0.4628 - lr: 2.0000e-06\n",
      "Epoch 18/200\n",
      "68/68 [==============================] - ETA: 0s - loss: 1.0961 - accuracy: 0.5048\n",
      "Epoch 18: accuracy did not improve from 0.53309\n",
      "68/68 [==============================] - 17s 252ms/step - loss: 1.0961 - accuracy: 0.5048 - val_loss: 1.0986 - val_accuracy: 0.5056 - lr: 2.0000e-06\n",
      "Epoch 19/200\n",
      "68/68 [==============================] - ETA: 0s - loss: 1.0924 - accuracy: 0.5085\n",
      "Epoch 19: accuracy did not improve from 0.53309\n",
      "68/68 [==============================] - 17s 254ms/step - loss: 1.0924 - accuracy: 0.5085 - val_loss: 1.0986 - val_accuracy: 0.5186 - lr: 2.0000e-06\n",
      "Epoch 20/200\n",
      "68/68 [==============================] - ETA: 0s - loss: 1.0938 - accuracy: 0.5173\n",
      "Epoch 20: accuracy did not improve from 0.53309\n",
      "68/68 [==============================] - 17s 251ms/step - loss: 1.0938 - accuracy: 0.5173 - val_loss: 1.0986 - val_accuracy: 0.4907 - lr: 2.0000e-06\n",
      "Epoch 21/200\n",
      "68/68 [==============================] - ETA: 0s - loss: 1.0932 - accuracy: 0.5231\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 1.9999999949504855e-07.\n",
      "\n",
      "Epoch 21: accuracy did not improve from 0.53309\n",
      "68/68 [==============================] - 17s 251ms/step - loss: 1.0932 - accuracy: 0.5231 - val_loss: 1.0986 - val_accuracy: 0.5149 - lr: 2.0000e-06\n",
      "Epoch 22/200\n",
      "68/68 [==============================] - ETA: 0s - loss: 1.0934 - accuracy: 0.5247\n",
      "Epoch 22: accuracy did not improve from 0.53309\n",
      "68/68 [==============================] - 17s 253ms/step - loss: 1.0934 - accuracy: 0.5247 - val_loss: 1.0986 - val_accuracy: 0.5297 - lr: 2.0000e-07\n",
      "Epoch 23/200\n",
      "68/68 [==============================] - ETA: 0s - loss: 1.0932 - accuracy: 0.5096\n",
      "Epoch 23: accuracy did not improve from 0.53309\n",
      "68/68 [==============================] - 17s 255ms/step - loss: 1.0932 - accuracy: 0.5096 - val_loss: 1.0986 - val_accuracy: 0.5056 - lr: 2.0000e-07\n",
      "Epoch 24/200\n",
      "68/68 [==============================] - ETA: 0s - loss: 1.0919 - accuracy: 0.5113\n",
      "Epoch 24: accuracy did not improve from 0.53309\n",
      "68/68 [==============================] - 17s 252ms/step - loss: 1.0919 - accuracy: 0.5113 - val_loss: 1.0986 - val_accuracy: 0.5186 - lr: 2.0000e-07\n",
      "Epoch 25/200\n",
      "68/68 [==============================] - ETA: 0s - loss: 1.0934 - accuracy: 0.5189\n",
      "Epoch 25: accuracy did not improve from 0.53309\n",
      "68/68 [==============================] - 17s 251ms/step - loss: 1.0934 - accuracy: 0.5189 - val_loss: 1.0986 - val_accuracy: 0.4851 - lr: 2.0000e-07\n",
      "Epoch 26/200\n",
      "68/68 [==============================] - ETA: 0s - loss: 1.0922 - accuracy: 0.5157\n",
      "Epoch 26: accuracy did not improve from 0.53309\n",
      "68/68 [==============================] - 17s 252ms/step - loss: 1.0922 - accuracy: 0.5157 - val_loss: 1.0986 - val_accuracy: 0.5223 - lr: 2.0000e-07\n",
      "Epoch 27/200\n",
      "68/68 [==============================] - ETA: 0s - loss: 1.0942 - accuracy: 0.5082\n",
      "Epoch 27: accuracy did not improve from 0.53309\n",
      "68/68 [==============================] - 17s 255ms/step - loss: 1.0942 - accuracy: 0.5082 - val_loss: 1.0986 - val_accuracy: 0.5000 - lr: 2.0000e-07\n",
      "Epoch 28/200\n",
      "68/68 [==============================] - ETA: 0s - loss: 1.0940 - accuracy: 0.5245\n",
      "Epoch 28: accuracy did not improve from 0.53309\n",
      "68/68 [==============================] - 17s 252ms/step - loss: 1.0940 - accuracy: 0.5245 - val_loss: 1.0986 - val_accuracy: 0.5112 - lr: 2.0000e-07\n",
      "Epoch 29/200\n",
      "68/68 [==============================] - ETA: 0s - loss: 1.0943 - accuracy: 0.5115\n",
      "Epoch 29: accuracy did not improve from 0.53309\n",
      "68/68 [==============================] - 17s 253ms/step - loss: 1.0943 - accuracy: 0.5115 - val_loss: 1.0986 - val_accuracy: 0.4888 - lr: 2.0000e-07\n",
      "Epoch 30/200\n",
      "68/68 [==============================] - ETA: 0s - loss: 1.0943 - accuracy: 0.5159\n",
      "Epoch 30: accuracy did not improve from 0.53309\n",
      "68/68 [==============================] - 17s 252ms/step - loss: 1.0943 - accuracy: 0.5159 - val_loss: 1.0986 - val_accuracy: 0.5409 - lr: 2.0000e-07\n",
      "Epoch 31/200\n",
      "68/68 [==============================] - ETA: 0s - loss: 1.0935 - accuracy: 0.5157\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 2.000000023372195e-08.\n",
      "\n",
      "Epoch 31: accuracy did not improve from 0.53309\n",
      "68/68 [==============================] - 17s 253ms/step - loss: 1.0935 - accuracy: 0.5157 - val_loss: 1.0986 - val_accuracy: 0.5112 - lr: 2.0000e-07\n",
      "Epoch 32/200\n",
      "68/68 [==============================] - ETA: 0s - loss: 1.0934 - accuracy: 0.5164\n",
      "Epoch 32: accuracy did not improve from 0.53309\n",
      "68/68 [==============================] - 17s 252ms/step - loss: 1.0934 - accuracy: 0.5164 - val_loss: 1.0986 - val_accuracy: 0.5074 - lr: 2.0000e-08\n",
      "Epoch 33/200\n",
      "68/68 [==============================] - ETA: 0s - loss: 1.0975 - accuracy: 0.5168\n",
      "Epoch 33: accuracy did not improve from 0.53309\n",
      "68/68 [==============================] - 17s 253ms/step - loss: 1.0975 - accuracy: 0.5168 - val_loss: 1.0986 - val_accuracy: 0.5390 - lr: 2.0000e-08\n",
      "Epoch 34/200\n",
      "68/68 [==============================] - ETA: 0s - loss: 1.0924 - accuracy: 0.5205\n",
      "Epoch 34: accuracy did not improve from 0.53309\n",
      "68/68 [==============================] - 17s 252ms/step - loss: 1.0924 - accuracy: 0.5205 - val_loss: 1.0986 - val_accuracy: 0.4981 - lr: 2.0000e-08\n",
      "Epoch 35/200\n",
      "68/68 [==============================] - ETA: 0s - loss: 1.0932 - accuracy: 0.5150\n",
      "Epoch 35: accuracy did not improve from 0.53309\n",
      "68/68 [==============================] - 17s 253ms/step - loss: 1.0932 - accuracy: 0.5150 - val_loss: 1.0986 - val_accuracy: 0.4851 - lr: 2.0000e-08\n",
      "Epoch 36/200\n",
      "68/68 [==============================] - ETA: 0s - loss: 1.0942 - accuracy: 0.5178\n",
      "Epoch 36: accuracy did not improve from 0.53309\n",
      "68/68 [==============================] - 18s 259ms/step - loss: 1.0942 - accuracy: 0.5178 - val_loss: 1.0986 - val_accuracy: 0.5037 - lr: 2.0000e-08\n",
      "Epoch 37/200\n",
      "68/68 [==============================] - ETA: 0s - loss: 1.0929 - accuracy: 0.5252\n",
      "Epoch 37: accuracy did not improve from 0.53309\n",
      "68/68 [==============================] - 17s 252ms/step - loss: 1.0929 - accuracy: 0.5252 - val_loss: 1.0986 - val_accuracy: 0.5279 - lr: 2.0000e-08\n",
      "Epoch 38/200\n",
      "68/68 [==============================] - ETA: 0s - loss: 1.0992 - accuracy: 0.5182\n",
      "Epoch 38: accuracy did not improve from 0.53309\n",
      "68/68 [==============================] - 18s 257ms/step - loss: 1.0992 - accuracy: 0.5182 - val_loss: 1.0986 - val_accuracy: 0.4833 - lr: 2.0000e-08\n",
      "Epoch 39/200\n",
      " 2/68 [..............................] - ETA: 12s - loss: 1.0898 - accuracy: 0.5234"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32me:\\AI\\ClubIA\\Notebooks\\PreProcess.ipynb Cell 7'\u001b[0m in \u001b[0;36m<cell line: 45>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/AI/ClubIA/Notebooks/PreProcess.ipynb#ch0000006?line=35'>36</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/AI/ClubIA/Notebooks/PreProcess.ipynb#ch0000006?line=36'>37</a>\u001b[0m   loss\u001b[39m=\u001b[39mloss,\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/AI/ClubIA/Notebooks/PreProcess.ipynb#ch0000006?line=37'>38</a>\u001b[0m   optimizer\u001b[39m=\u001b[39moptimizer,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/AI/ClubIA/Notebooks/PreProcess.ipynb#ch0000006?line=41'>42</a>\u001b[0m   ],\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/AI/ClubIA/Notebooks/PreProcess.ipynb#ch0000006?line=42'>43</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/AI/ClubIA/Notebooks/PreProcess.ipynb#ch0000006?line=43'>44</a>\u001b[0m BATCH \u001b[39m=\u001b[39m \u001b[39m64\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/AI/ClubIA/Notebooks/PreProcess.ipynb#ch0000006?line=44'>45</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/AI/ClubIA/Notebooks/PreProcess.ipynb#ch0000006?line=45'>46</a>\u001b[0m   epochs\u001b[39m=\u001b[39;49m\u001b[39m200\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/AI/ClubIA/Notebooks/PreProcess.ipynb#ch0000006?line=46'>47</a>\u001b[0m   callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/AI/ClubIA/Notebooks/PreProcess.ipynb#ch0000006?line=47'>48</a>\u001b[0m   x\u001b[39m=\u001b[39;49mtrain_ds\u001b[39m.\u001b[39;49mbatch(BATCH),\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/AI/ClubIA/Notebooks/PreProcess.ipynb#ch0000006?line=48'>49</a>\u001b[0m   validation_data\u001b[39m=\u001b[39;49mvalid_ds\u001b[39m.\u001b[39;49mbatch(BATCH),\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/AI/ClubIA/Notebooks/PreProcess.ipynb#ch0000006?line=49'>50</a>\u001b[0m )\n",
      "File \u001b[1;32mE:\\Anaconda\\envs\\tfClub\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     <a href='file:///e%3A/Anaconda/envs/tfClub/lib/site-packages/keras/utils/traceback_utils.py?line=61'>62</a>\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     <a href='file:///e%3A/Anaconda/envs/tfClub/lib/site-packages/keras/utils/traceback_utils.py?line=62'>63</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> <a href='file:///e%3A/Anaconda/envs/tfClub/lib/site-packages/keras/utils/traceback_utils.py?line=63'>64</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     <a href='file:///e%3A/Anaconda/envs/tfClub/lib/site-packages/keras/utils/traceback_utils.py?line=64'>65</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     <a href='file:///e%3A/Anaconda/envs/tfClub/lib/site-packages/keras/utils/traceback_utils.py?line=65'>66</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mE:\\Anaconda\\envs\\tfClub\\lib\\site-packages\\keras\\engine\\training.py:1389\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   <a href='file:///e%3A/Anaconda/envs/tfClub/lib/site-packages/keras/engine/training.py?line=1386'>1387</a>\u001b[0m logs \u001b[39m=\u001b[39m tmp_logs  \u001b[39m# No error, now safe to assign to logs.\u001b[39;00m\n\u001b[0;32m   <a href='file:///e%3A/Anaconda/envs/tfClub/lib/site-packages/keras/engine/training.py?line=1387'>1388</a>\u001b[0m end_step \u001b[39m=\u001b[39m step \u001b[39m+\u001b[39m data_handler\u001b[39m.\u001b[39mstep_increment\n\u001b[1;32m-> <a href='file:///e%3A/Anaconda/envs/tfClub/lib/site-packages/keras/engine/training.py?line=1388'>1389</a>\u001b[0m callbacks\u001b[39m.\u001b[39;49mon_train_batch_end(end_step, logs)\n\u001b[0;32m   <a href='file:///e%3A/Anaconda/envs/tfClub/lib/site-packages/keras/engine/training.py?line=1389'>1390</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstop_training:\n\u001b[0;32m   <a href='file:///e%3A/Anaconda/envs/tfClub/lib/site-packages/keras/engine/training.py?line=1390'>1391</a>\u001b[0m   \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mE:\\Anaconda\\envs\\tfClub\\lib\\site-packages\\keras\\callbacks.py:438\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    <a href='file:///e%3A/Anaconda/envs/tfClub/lib/site-packages/keras/callbacks.py?line=430'>431</a>\u001b[0m \u001b[39m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[0;32m    <a href='file:///e%3A/Anaconda/envs/tfClub/lib/site-packages/keras/callbacks.py?line=431'>432</a>\u001b[0m \n\u001b[0;32m    <a href='file:///e%3A/Anaconda/envs/tfClub/lib/site-packages/keras/callbacks.py?line=432'>433</a>\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m    <a href='file:///e%3A/Anaconda/envs/tfClub/lib/site-packages/keras/callbacks.py?line=433'>434</a>\u001b[0m \u001b[39m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[0;32m    <a href='file:///e%3A/Anaconda/envs/tfClub/lib/site-packages/keras/callbacks.py?line=434'>435</a>\u001b[0m \u001b[39m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[0;32m    <a href='file:///e%3A/Anaconda/envs/tfClub/lib/site-packages/keras/callbacks.py?line=435'>436</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    <a href='file:///e%3A/Anaconda/envs/tfClub/lib/site-packages/keras/callbacks.py?line=436'>437</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[1;32m--> <a href='file:///e%3A/Anaconda/envs/tfClub/lib/site-packages/keras/callbacks.py?line=437'>438</a>\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook(ModeKeys\u001b[39m.\u001b[39;49mTRAIN, \u001b[39m'\u001b[39;49m\u001b[39mend\u001b[39;49m\u001b[39m'\u001b[39;49m, batch, logs\u001b[39m=\u001b[39;49mlogs)\n",
      "File \u001b[1;32mE:\\Anaconda\\envs\\tfClub\\lib\\site-packages\\keras\\callbacks.py:297\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    <a href='file:///e%3A/Anaconda/envs/tfClub/lib/site-packages/keras/callbacks.py?line=294'>295</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[0;32m    <a href='file:///e%3A/Anaconda/envs/tfClub/lib/site-packages/keras/callbacks.py?line=295'>296</a>\u001b[0m \u001b[39melif\u001b[39;00m hook \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mend\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m--> <a href='file:///e%3A/Anaconda/envs/tfClub/lib/site-packages/keras/callbacks.py?line=296'>297</a>\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_end_hook(mode, batch, logs)\n\u001b[0;32m    <a href='file:///e%3A/Anaconda/envs/tfClub/lib/site-packages/keras/callbacks.py?line=297'>298</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///e%3A/Anaconda/envs/tfClub/lib/site-packages/keras/callbacks.py?line=298'>299</a>\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    <a href='file:///e%3A/Anaconda/envs/tfClub/lib/site-packages/keras/callbacks.py?line=299'>300</a>\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mUnrecognized hook: \u001b[39m\u001b[39m{\u001b[39;00mhook\u001b[39m}\u001b[39;00m\u001b[39m. Expected values are [\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbegin\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mend\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m]\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mE:\\Anaconda\\envs\\tfClub\\lib\\site-packages\\keras\\callbacks.py:318\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    <a href='file:///e%3A/Anaconda/envs/tfClub/lib/site-packages/keras/callbacks.py?line=314'>315</a>\u001b[0m   batch_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_start_time\n\u001b[0;32m    <a href='file:///e%3A/Anaconda/envs/tfClub/lib/site-packages/keras/callbacks.py?line=315'>316</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_times\u001b[39m.\u001b[39mappend(batch_time)\n\u001b[1;32m--> <a href='file:///e%3A/Anaconda/envs/tfClub/lib/site-packages/keras/callbacks.py?line=317'>318</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook_helper(hook_name, batch, logs)\n\u001b[0;32m    <a href='file:///e%3A/Anaconda/envs/tfClub/lib/site-packages/keras/callbacks.py?line=319'>320</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_times) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_batches_for_timing_check:\n\u001b[0;32m    <a href='file:///e%3A/Anaconda/envs/tfClub/lib/site-packages/keras/callbacks.py?line=320'>321</a>\u001b[0m   end_hook_name \u001b[39m=\u001b[39m hook_name\n",
      "File \u001b[1;32mE:\\Anaconda\\envs\\tfClub\\lib\\site-packages\\keras\\callbacks.py:356\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    <a href='file:///e%3A/Anaconda/envs/tfClub/lib/site-packages/keras/callbacks.py?line=353'>354</a>\u001b[0m \u001b[39mfor\u001b[39;00m callback \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallbacks:\n\u001b[0;32m    <a href='file:///e%3A/Anaconda/envs/tfClub/lib/site-packages/keras/callbacks.py?line=354'>355</a>\u001b[0m   hook \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(callback, hook_name)\n\u001b[1;32m--> <a href='file:///e%3A/Anaconda/envs/tfClub/lib/site-packages/keras/callbacks.py?line=355'>356</a>\u001b[0m   hook(batch, logs)\n\u001b[0;32m    <a href='file:///e%3A/Anaconda/envs/tfClub/lib/site-packages/keras/callbacks.py?line=357'>358</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_timing:\n\u001b[0;32m    <a href='file:///e%3A/Anaconda/envs/tfClub/lib/site-packages/keras/callbacks.py?line=358'>359</a>\u001b[0m   \u001b[39mif\u001b[39;00m hook_name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_hook_times:\n",
      "File \u001b[1;32mE:\\Anaconda\\envs\\tfClub\\lib\\site-packages\\keras\\callbacks.py:1034\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   <a href='file:///e%3A/Anaconda/envs/tfClub/lib/site-packages/keras/callbacks.py?line=1032'>1033</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mon_train_batch_end\u001b[39m(\u001b[39mself\u001b[39m, batch, logs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m-> <a href='file:///e%3A/Anaconda/envs/tfClub/lib/site-packages/keras/callbacks.py?line=1033'>1034</a>\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_update_progbar(batch, logs)\n",
      "File \u001b[1;32mE:\\Anaconda\\envs\\tfClub\\lib\\site-packages\\keras\\callbacks.py:1106\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   <a href='file:///e%3A/Anaconda/envs/tfClub/lib/site-packages/keras/callbacks.py?line=1101'>1102</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseen \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m add_seen\n\u001b[0;32m   <a href='file:///e%3A/Anaconda/envs/tfClub/lib/site-packages/keras/callbacks.py?line=1103'>1104</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   <a href='file:///e%3A/Anaconda/envs/tfClub/lib/site-packages/keras/callbacks.py?line=1104'>1105</a>\u001b[0m   \u001b[39m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[1;32m-> <a href='file:///e%3A/Anaconda/envs/tfClub/lib/site-packages/keras/callbacks.py?line=1105'>1106</a>\u001b[0m   logs \u001b[39m=\u001b[39m tf_utils\u001b[39m.\u001b[39;49msync_to_numpy_or_python_type(logs)\n\u001b[0;32m   <a href='file:///e%3A/Anaconda/envs/tfClub/lib/site-packages/keras/callbacks.py?line=1106'>1107</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprogbar\u001b[39m.\u001b[39mupdate(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseen, \u001b[39mlist\u001b[39m(logs\u001b[39m.\u001b[39mitems()), finalize\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mE:\\Anaconda\\envs\\tfClub\\lib\\site-packages\\keras\\utils\\tf_utils.py:563\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    <a href='file:///e%3A/Anaconda/envs/tfClub/lib/site-packages/keras/utils/tf_utils.py?line=559'>560</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m t\n\u001b[0;32m    <a href='file:///e%3A/Anaconda/envs/tfClub/lib/site-packages/keras/utils/tf_utils.py?line=560'>561</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mitem() \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mndim(t) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m t\n\u001b[1;32m--> <a href='file:///e%3A/Anaconda/envs/tfClub/lib/site-packages/keras/utils/tf_utils.py?line=562'>563</a>\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49mnest\u001b[39m.\u001b[39;49mmap_structure(_to_single_numpy_or_python_type, tensors)\n",
      "File \u001b[1;32mE:\\Anaconda\\envs\\tfClub\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:914\u001b[0m, in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///e%3A/Anaconda/envs/tfClub/lib/site-packages/tensorflow/python/util/nest.py?line=909'>910</a>\u001b[0m flat_structure \u001b[39m=\u001b[39m (flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[0;32m    <a href='file:///e%3A/Anaconda/envs/tfClub/lib/site-packages/tensorflow/python/util/nest.py?line=910'>911</a>\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[0;32m    <a href='file:///e%3A/Anaconda/envs/tfClub/lib/site-packages/tensorflow/python/util/nest.py?line=912'>913</a>\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> <a href='file:///e%3A/Anaconda/envs/tfClub/lib/site-packages/tensorflow/python/util/nest.py?line=913'>914</a>\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[0;32m    <a href='file:///e%3A/Anaconda/envs/tfClub/lib/site-packages/tensorflow/python/util/nest.py?line=914'>915</a>\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32mE:\\Anaconda\\envs\\tfClub\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:914\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    <a href='file:///e%3A/Anaconda/envs/tfClub/lib/site-packages/tensorflow/python/util/nest.py?line=909'>910</a>\u001b[0m flat_structure \u001b[39m=\u001b[39m (flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[0;32m    <a href='file:///e%3A/Anaconda/envs/tfClub/lib/site-packages/tensorflow/python/util/nest.py?line=910'>911</a>\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[0;32m    <a href='file:///e%3A/Anaconda/envs/tfClub/lib/site-packages/tensorflow/python/util/nest.py?line=912'>913</a>\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> <a href='file:///e%3A/Anaconda/envs/tfClub/lib/site-packages/tensorflow/python/util/nest.py?line=913'>914</a>\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39;49mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[0;32m    <a href='file:///e%3A/Anaconda/envs/tfClub/lib/site-packages/tensorflow/python/util/nest.py?line=914'>915</a>\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32mE:\\Anaconda\\envs\\tfClub\\lib\\site-packages\\keras\\utils\\tf_utils.py:557\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    <a href='file:///e%3A/Anaconda/envs/tfClub/lib/site-packages/keras/utils/tf_utils.py?line=553'>554</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[0;32m    <a href='file:///e%3A/Anaconda/envs/tfClub/lib/site-packages/keras/utils/tf_utils.py?line=554'>555</a>\u001b[0m   \u001b[39m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[0;32m    <a href='file:///e%3A/Anaconda/envs/tfClub/lib/site-packages/keras/utils/tf_utils.py?line=555'>556</a>\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(t, tf\u001b[39m.\u001b[39mTensor):\n\u001b[1;32m--> <a href='file:///e%3A/Anaconda/envs/tfClub/lib/site-packages/keras/utils/tf_utils.py?line=556'>557</a>\u001b[0m     t \u001b[39m=\u001b[39m t\u001b[39m.\u001b[39;49mnumpy()\n\u001b[0;32m    <a href='file:///e%3A/Anaconda/envs/tfClub/lib/site-packages/keras/utils/tf_utils.py?line=557'>558</a>\u001b[0m   \u001b[39m# Strings, ragged and sparse tensors don't have .item(). Return them as-is.\u001b[39;00m\n\u001b[0;32m    <a href='file:///e%3A/Anaconda/envs/tfClub/lib/site-packages/keras/utils/tf_utils.py?line=558'>559</a>\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(t, (np\u001b[39m.\u001b[39mndarray, np\u001b[39m.\u001b[39mgeneric)):\n",
      "File \u001b[1;32mE:\\Anaconda\\envs\\tfClub\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1223\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   <a href='file:///e%3A/Anaconda/envs/tfClub/lib/site-packages/tensorflow/python/framework/ops.py?line=1199'>1200</a>\u001b[0m \u001b[39m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[0;32m   <a href='file:///e%3A/Anaconda/envs/tfClub/lib/site-packages/tensorflow/python/framework/ops.py?line=1200'>1201</a>\u001b[0m \n\u001b[0;32m   <a href='file:///e%3A/Anaconda/envs/tfClub/lib/site-packages/tensorflow/python/framework/ops.py?line=1201'>1202</a>\u001b[0m \u001b[39mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   <a href='file:///e%3A/Anaconda/envs/tfClub/lib/site-packages/tensorflow/python/framework/ops.py?line=1219'>1220</a>\u001b[0m \u001b[39m    NumPy dtype.\u001b[39;00m\n\u001b[0;32m   <a href='file:///e%3A/Anaconda/envs/tfClub/lib/site-packages/tensorflow/python/framework/ops.py?line=1220'>1221</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   <a href='file:///e%3A/Anaconda/envs/tfClub/lib/site-packages/tensorflow/python/framework/ops.py?line=1221'>1222</a>\u001b[0m \u001b[39m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[1;32m-> <a href='file:///e%3A/Anaconda/envs/tfClub/lib/site-packages/tensorflow/python/framework/ops.py?line=1222'>1223</a>\u001b[0m maybe_arr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   <a href='file:///e%3A/Anaconda/envs/tfClub/lib/site-packages/tensorflow/python/framework/ops.py?line=1223'>1224</a>\u001b[0m \u001b[39mreturn\u001b[39;00m maybe_arr\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(maybe_arr, np\u001b[39m.\u001b[39mndarray) \u001b[39melse\u001b[39;00m maybe_arr\n",
      "File \u001b[1;32mE:\\Anaconda\\envs\\tfClub\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1189\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   <a href='file:///e%3A/Anaconda/envs/tfClub/lib/site-packages/tensorflow/python/framework/ops.py?line=1186'>1187</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_numpy\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m   <a href='file:///e%3A/Anaconda/envs/tfClub/lib/site-packages/tensorflow/python/framework/ops.py?line=1187'>1188</a>\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> <a href='file:///e%3A/Anaconda/envs/tfClub/lib/site-packages/tensorflow/python/framework/ops.py?line=1188'>1189</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy_internal()\n\u001b[0;32m   <a href='file:///e%3A/Anaconda/envs/tfClub/lib/site-packages/tensorflow/python/framework/ops.py?line=1189'>1190</a>\u001b[0m   \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   <a href='file:///e%3A/Anaconda/envs/tfClub/lib/site-packages/tensorflow/python/framework/ops.py?line=1190'>1191</a>\u001b[0m     \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "LEARNING_RATE = 0.0000200 #0.0000100\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "  learning_rate=LEARNING_RATE,\n",
    ")\n",
    "input_shape = (None, SIZE_IMG, SIZE_IMG, 3)\n",
    "\n",
    "model = VitModel(\n",
    "  transformer_layers=TRANSFORMER_LAYERS,\n",
    "  patch_size=PATCH_SIZE,\n",
    "  num_patches=NUM_PATCHES,\n",
    "  projection_dim=PROJECTION_DIM,\n",
    "  transformer_units=TRANSFORMER_UNITS,\n",
    "  num_heads=NUM_HEADS,\n",
    "  mlp_head_units=MLP_HEAD_UNITS,\n",
    "  num_classes=len(class_array),\n",
    "  input_shape=(SIZE_IMG, SIZE_IMG, 3),\n",
    ")\n",
    "model.build(input_shape)\n",
    "\n",
    "check_name = f'checkpoints/{len(class_array)}_{MLP_HEAD_UNITS}_{TRANSFORMER_LAYERS}_trans_{NUM_HEADS}_heads_{NUM_PATCHES}_num_patchs_{PROJECTION_DIM}_{LEARNING_RATE}checkpoint.h5'\n",
    "logdir = \"./logs\" + \"/\" + time.strftime(\"%Y%m%d_%H-%M-%S\")\n",
    "callbacks = [\n",
    "  ReduceLROnPlateau(verbose=1),\n",
    "  #EarlyStopping(patience=10, verbose=1),\n",
    "  ModelCheckpoint(\n",
    "    check_name,\n",
    "    verbose=1,\n",
    "    monitor='accuracy',\n",
    "    save_freq='epoch',\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "  ),\n",
    "  TensorBoard(log_dir=logdir, histogram_freq=1)\n",
    "]\n",
    "model.compile(\n",
    "  loss=loss,\n",
    "  optimizer=optimizer,\n",
    "  metrics=[\n",
    "    tf.keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\"),\n",
    "    #tf.keras.metrics.SparseTopKCategoricalAccuracy(5, name=\"top-5-accuracy\"),\n",
    "  ],\n",
    ")\n",
    "BATCH = 64\n",
    "model.fit(\n",
    "  epochs=200,\n",
    "  callbacks=callbacks,\n",
    "  x=train_ds.batch(BATCH),\n",
    "  validation_data=valid_ds.batch(BATCH),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tf_record_eva = test_ds.batch(256)\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "for images, label in tf_record_eva:\n",
    "  preds = model.predict(images)\n",
    "  all_labels.extend(label)\n",
    "  all_preds.extend(np.argmax(preds, axis=1))\n",
    "del tf_record_eva\n",
    "\n",
    "confusion_matrix = tf.math.confusion_matrix(all_labels, all_preds, num_classes=len(class_array))\n",
    "\n",
    "plt.figure(figsize=(25, 10))\n",
    "sns.heatmap(confusion_matrix.numpy(), annot=True, cmap='Blues', xticklabels=class_array, yticklabels=class_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "  '../Bases de Datos/crisismmd_datasplit_agreed_label/task_humanitarian_text_img_agreed_lab_dev.tsv',\n",
    "  sep='\\t',\n",
    "  encoding='utf-8'\n",
    ")\n",
    "\n",
    "print('Previous: ', df['tweet_text'].iloc[15])\n",
    "df['tweet_clean'] = df['tweet_text'].apply(clean_str)\n",
    "print('After: ', df['tweet_clean'].iloc[15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_url = \"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\"\n",
    "encoder_url = \"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_preprocess_model = hub.KerasLayer(preprocess_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_test = list(df['tweet_clean'].values)\n",
    "len(text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_preprocessed = bert_preprocess_model(text_test)\n",
    "text_preprocessed.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = hub.KerasLayer(encoder_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#light test of the layer\n",
    "result_bert = bert_model(text_preprocessed)\n",
    "result_bert.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_bert['pooled_output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_bert['encoder_outputs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_bert['sequence_output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = 100\n",
    "\n",
    "bert_results = []\n",
    "for i in range(0, len(text_test), chunks):\n",
    "  text_chunk = None\n",
    "  if i == len(text_test) - chunks:\n",
    "    text_chunk = text_test[i:]\n",
    "  else:\n",
    "    text_chunk = text_test[i: i + chunks]\n",
    "\n",
    "  text_preprocessed = bert_preprocess_model(text_chunk)\n",
    "  result_bert = bert_model(text_preprocessed)\n",
    "  bert_results.append(result_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(bert_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_results[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda.select_device(0)\n",
    "cuda.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import vgg16\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "model = VGG19()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import load_img\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "import numpy as np\n",
    "\n",
    "image = load_img('../Data/Naruto_Uzumaki_HD.webp', target_size=(224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = np.array(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = np.array([image])\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = preprocess_input(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.predict(image)\n",
    "result[0].shape\n",
    "#the output is a vector of features (1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "852bc408046ca7dfc5c8f91ce764d8630d2287ca09c7fe9d1b4d9cd156705bcb"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 ('tfenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
